{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom Transcript Format Cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: John K. Wagner, jkwagner@unm.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following notebook is designed to format Zoom transcripts so that each speakers words are concatenated rather than being frequently separated. \n",
    " \n",
    "### For this to work properly, the provided Zoom transcripts will need to have the *.txt* extension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Data management & manipulation\n",
    "import os #General cmds\n",
    "import re #Regex\n",
    "from pathlib import Path #File/directory utility\n",
    "from docx import Document #Exporting word docs (.docx)\n",
    "from tqdm import tqdm #Progress bar for main loop\n",
    "from ipyfilechooser import FileChooser #Browsing to file path (same for below two)\n",
    "import ipywidgets as widgets #For choosing output type(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Folder Selection\n",
    "These functions will allow you to select a folder where the transcripts are intially, and a folder where you want the files after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display a FileChooser widget\n",
    "fc_transcripts = FileChooser()\n",
    "fc_transcripts.show_only_dirs = True\n",
    "\n",
    "fc_destination = FileChooser()\n",
    "fc_destination.show_only_dirs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Folder Containing Original Transcripts (.txt extensions required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5af4bde85648519e23297ba7b67820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='C:\\Users\\deere\\Dropbox\\SOE_climate_study\\Transcript Cleaner', filename='', title='HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fc_transcripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Folder to Output Modified Transcripts To (Original Folder Structure Will Be Mirrored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b436b8c67845f999727aec798ed41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='C:\\Users\\deere\\Dropbox\\SOE_climate_study\\Transcript Cleaner', filename='', title='HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fc_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Output Format(s)\n",
    "Please select either the .txt and/or .docx formats to output to the output folder from the checkboxes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the output format of your choice. You may select both\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6d2754469b4640934f5d0172263846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='.txt'), Checkbox(value=False, description='.docx')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkbox_txt = widgets.Checkbox(description = \".txt\")\n",
    "checkbox_docx = widgets.Checkbox(description = \".docx\")\n",
    "boxes = widgets.VBox([checkbox_txt, checkbox_docx])\n",
    "print(\"Please select the output format of your choice. You may select both\")\n",
    "boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Provided Folders\n",
    "First we convert the folders to strings for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_folder = str(fc_transcripts.selected_path)\n",
    "output_folder = str(fc_destination.selected_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we check to make sure directories were provided properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders sucessfully verified\n"
     ]
    }
   ],
   "source": [
    "isDirectory_transcript = os.path.isdir(str(transcript_folder))\n",
    "isDirectory_output = os.path.isdir(str(output_folder))\n",
    "\n",
    "if isDirectory_output == True:\n",
    "    if isDirectory_transcript == True:\n",
    "        print(\"Folders sucessfully verified\")\n",
    "    else:\n",
    "        try:\n",
    "            x = 1/0\n",
    "        except:\n",
    "            print(\"Error: invalid original transcript folder provided.\")\n",
    "else:\n",
    "    try:\n",
    "        x = 1/0\n",
    "    except:\n",
    "        print(\"Error: invalid destination transcript folder provided.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up File List (Based on transcript_folder Directory)\n",
    "First we make a path object to the folder containing our transcripts (it just identifies any .txt files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_folder = Path(transcript_folder).rglob('*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a list of files in that folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in txt_folder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also transform output_folder and transcript_folder to path objects for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(output_folder)\n",
    "base_dir = Path(transcript_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop for Reading, Transforming, and Saving Each Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 87/87 [00:08<00:00, 10.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# This loop reads the file line by line, and stores the result as a list called *content*\n",
    "for file in tqdm(files):\n",
    "    f = open(file, 'r')  \n",
    "    content = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    ####\n",
    "    # Convert List to String\n",
    "    content_str = \"\" # Create blank string to fill in\n",
    "    for i in content: # Loop appends each list element in content to the string, content_str\n",
    "        content_str += i\n",
    "    \n",
    "    #####\n",
    "    ## Regex Patterns stored as Regex objects for identifying our three main parts of a speaking instance\n",
    "\n",
    "    # -- for recognzing the number ahead of each speaking instance (based on line containing one number {1-11 digits} and /n only)\n",
    "    num_pattern = re.compile(r'^[1-9]\\d{0,11}\\n', re.MULTILINE)\n",
    "    # -- for recognzing the time period of each speaking instance (based on time period format)\n",
    "    time_pattern = re.compile(r'(^\\d\\d:\\d\\d:\\d\\d.\\d\\d\\d --> \\d\\d:\\d\\d:\\d\\d.\\d\\d\\d\\n)', re.MULTILINE)\n",
    "    # -- for recognzing the speaking instance itself (it's the line after the time)\n",
    "    blurb_pattern = re.compile(r'^\\d\\d:\\d\\d:\\d\\d.\\d\\d\\d --> \\d\\d:\\d\\d:\\d\\d.\\d\\d\\d[\\r\\n]+([^\\r\\n]+)', re.MULTILINE)\n",
    "\n",
    "    #####\n",
    "    ## Apply each pattern to content_str, store each as a list\n",
    "    num_temp = num_pattern.findall(content_str)\n",
    "    time_temp = time_pattern.findall(content_str)\n",
    "    blurb_temp = blurb_pattern.findall(content_str)\n",
    "    \n",
    "    ####\n",
    "    # Transform our resulting three lists into a pandas dataframe for easier transformations\n",
    "    df = pd.DataFrame({'Speech_Num': num_temp, 'Time' : time_temp, 'Speech' : blurb_temp})\n",
    "    \n",
    "    ####\n",
    "    ## Cleaning up and prepping columns\n",
    "\n",
    "    # -- Replacing errant newline characters\n",
    "    df['Speech_Num'] = df['Speech_Num'].str.replace(r'\\n', '')\n",
    "    df['Time'] = df['Time'].str.replace(r'\\n', '')\n",
    "\n",
    "    # Extracting the Speaker from the Speech Column\n",
    "    df['Speaker'] = df['Speech'].str.extract(r'^(.+?):')\n",
    "    # Extracting the Speech from the Speech Column (removing speaker)\n",
    "    df['Speech'] = df['Speech'].str.replace(r'^(.+?):', '')\n",
    "\n",
    "    # Separating Time Start and Time In for Later Tranformation\n",
    "    df ['Time_Start'] = df['Time'].str.extract(r'^(.+?) -->')\n",
    "    df ['Time_End'] = df['Time'].str.extract(r' --> (.*)')\n",
    "\n",
    "    # Check if prior speech instance had the same speaker (will allow us to collapse adjacent speakers' speaking instances ahead)\n",
    "    df['Speaker_Match'] = df.Speaker.eq(df.Speaker.shift())\n",
    "    \n",
    "    ####\n",
    "    ## Identifies speaking instances if prior speaker was the same one (for impending collapse)\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Identifying rows that are a new speaker\n",
    "        if row['Speaker_Match'] == False:\n",
    "            # Iterate Speaker Number by 1\n",
    "            i = i + 1\n",
    "            # Store Speaker Number\n",
    "            df.at[index, 'Speaker_Num'] = i\n",
    "        # Row is same speaker\n",
    "        else:\n",
    "            # Store Speaker Number\n",
    "            df.at[index, 'Speaker_Num'] = i \n",
    "            \n",
    "    ####\n",
    "    ## Group Dataset by Speaker Number\n",
    "    # Combine All Speech Blurbs per Speaker's Speaking Instance\n",
    "    collapsed_df = df.groupby(['Speaker_Num']).agg({'Speech': ''.join, 'Speaker' : 'first', 'Time_Start' : 'first', 'Time_End' : 'last'})\n",
    "\n",
    "    # Remove All Trailing and Leading Whitespace from Speeches\n",
    "    collapsed_df.replace(r\"^ +| +$\", r\"\", regex=True, inplace=True)\n",
    "    \n",
    "    ####\n",
    "    ## Creating Final String to Be Written to File\n",
    "\n",
    "    # Create an initial string containing the preamble\n",
    "    trnscpt_final = 'WEBVTT\\n\\n'\n",
    "\n",
    "    # Loop to add in the df strings\n",
    "    i = 0\n",
    "    for index, row in collapsed_df.iterrows():\n",
    "\n",
    "        # Add one to speaking instance number\n",
    "        i = i + 1\n",
    "\n",
    "        # Add speaking instance number to string\n",
    "        trnscpt_final = trnscpt_final + str(i) + '\\n'\n",
    "\n",
    "        # Add time elapsed to next line per speaking instance\n",
    "        trnscpt_final = trnscpt_final + row['Time_Start'] + ' --> ' + row['Time_End'] + '\\n'\n",
    "\n",
    "        # Add speaker to newline \n",
    "            # if speaker is not missing (this skips adding speaker when speaker is unknown):\n",
    "        if str(row['Speaker']) != 'nan':\n",
    "            trnscpt_final = trnscpt_final + str(row['Speaker']) + ': '\n",
    "\n",
    "        # Add Speech Blurb to newline\n",
    "        trnscpt_final = trnscpt_final + row['Speech'] + '\\n'\n",
    "\n",
    "        # Add newline between each speaking instance\n",
    "        trnscpt_final = trnscpt_final + '\\n'\n",
    "    \n",
    "    ####\n",
    "    ## Create Export File Locations\n",
    "        # Combine the desired path (output_dir) with the directory and file that go beyond our base directory(base_dir)\n",
    "    output_file_txt = output_dir.joinpath(Path(*file.parts[len(base_dir.parts):len(file.parts)]))\n",
    "        # Alter file extension from txt to docx for alternate (desired) output format\n",
    "    output_file_docx = output_file_txt.with_suffix('.docx')\n",
    "    \n",
    "    ####\n",
    "    ## Export .txt file [DISABLED FOR NOW]\n",
    "    if checkbox_txt.value == True: #Check if user desired .txt output\n",
    "        # Create missing folders if necessary in output directory\n",
    "        os.makedirs(os.path.dirname(output_file_txt), exist_ok=True)\n",
    "            # Open .txt for writing\n",
    "        text_file = open(output_file_txt, \"wt\")\n",
    "            # Write final transcript to file\n",
    "        n = text_file.write(trnscpt_final)\n",
    "            # Close file\n",
    "        text_file.close()\n",
    "    \n",
    "    ####\n",
    "    ## Export .docx file\n",
    "        #Check if user desired .docx output\n",
    "    if checkbox_docx.value == True:\n",
    "            # Create stored document to write to\n",
    "        document = Document()\n",
    "            # Write final transcript to body of docx (add_paragraph)\n",
    "        paragraph = document.add_paragraph(trnscpt_final)\n",
    "            # Write document to disk\n",
    "        document.save(output_file_docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
